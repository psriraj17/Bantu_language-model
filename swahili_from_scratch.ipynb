{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOA8wIwCSlEwWCmYF/hvKkH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/psriraj17/Bantu_language-model/blob/bantu-ssr/swahili_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The entire code in this file is extracted from 'https://github.com/gregfromstl/bantu-language-*modeling*'"
      ],
      "metadata": {
        "id": "tnMahm2ihmYu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VYW7Esnj9ME",
        "outputId": "faf5663e-6ad9-47c3-8134-fd2441de85e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PARAMS = {\n",
        "    'experiment_name': \"Swahili\",\n",
        "    'tags': [\"swahili\", \"from scratch\"],\n",
        "    'n': 1000,\n",
        "    'threshold': 750,\n",
        "    'train_iterations': 2,\n",
        "    'carry_hidden_state': False,\n",
        "    'val_split': 0.3,\n",
        "    'swahili_train': \"/content/drive/MyDrive/Colab Notebooks/train-04/sw-train.txt\",\n",
        "    'test_data': \"/content/drive/MyDrive/test04/sw-test.txt\"\n",
        "}"
      ],
      "metadata": {
        "id": "M-fnObgwkDKP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math"
      ],
      "metadata": {
        "id": "ARhibbKRkDIH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset():\n",
        "    def __init__(self, raw_data: str):\n",
        "        self.chars = set(list(set(raw_data)))\n",
        "        self.chars.add('~')\n",
        "        self.data_size, self.vocab_size = len(raw_data), len(self.chars)\n",
        "        print(\"{} characters, {} unique\".format(self.data_size, self.vocab_size))\n",
        "        \n",
        "        self.char_to_idx = { char: idx for idx, char in enumerate(self.chars) }\n",
        "        self.idx_to_char = { idx: char for idx, char in enumerate(self.chars) }\n",
        "        \n",
        "        self.data = [self.char_to_idx[char] for char in list(raw_data)]\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.data_size\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        return self.data[index]\n"
      ],
      "metadata": {
        "id": "EKGa8sp-kDF0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_data(raw_data: str, known_chars: str) -> str:\n",
        "    cleaned = \"\"\n",
        "    for char in raw_data:\n",
        "        if char not in known_chars:\n",
        "            cleaned += \"~\"\n",
        "        else:\n",
        "            cleaned += char\n",
        "    return cleaned"
      ],
      "metadata": {
        "id": "VGPwaPfBkDDP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Loading Swahili training data:\", end=\"\\n\\t\")\n",
        "raw_swahili = open(PARAMS['swahili_train'], 'r').read()[:10000000]\n",
        "swahili_train_size, swahili_val_size = int(len(raw_swahili)*(1-PARAMS['val_split'])), int(len(raw_swahili)*PARAMS['val_split'])\n",
        "\n",
        "train_data = Dataset(raw_swahili[:swahili_train_size])\n",
        "\n",
        "print(\"Loading Swahili validation data:\", end=\"\\n\\t\")\n",
        "cleaned_swahili_val_data = clean_data(raw_swahili[swahili_train_size:], train_data.chars)\n",
        "val_data = Dataset(cleaned_swahili_val_data)\n",
        "\n",
        "\n",
        "if len(PARAMS['test_data']) > 0:\n",
        "    print(\"Loading Testing data:\", end=\"\\n\\t\")\n",
        "    raw_test = open(PARAMS['test_data'], 'r').read()\n",
        "\n",
        "    cleaned_test_data = clean_data(raw_test, train_data.chars)\n",
        "    test_data = Dataset(cleaned_test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UpQqOnNkC9M",
        "outputId": "a86d7314-6547-4bb1-a275-330565f67d89"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Swahili training data:\n",
            "\t7000000 characters, 49 unique\n",
            "Loading Swahili validation data:\n",
            "\t3000000 characters, 49 unique\n",
            "Loading Testing data:\n",
            "\t3451383 characters, 49 unique\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CountMatrix:\n",
        "    def __init__(self, vocab: list, init_matrix=None):\n",
        "        self.counts = init_matrix if init_matrix is not None else {i:0 for i in vocab}\n",
        "        self.next = {i:None for i in vocab}"
      ],
      "metadata": {
        "id": "IcVvBwPCkC5i"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def increment_count(char: str, sequence: list, count_matrix: CountMatrix) -> list:\n",
        "    next_char = sequence[-1]\n",
        "    \n",
        "    count_matrix.counts[char] += 1\n",
        "    if count_matrix.next[next_char] is not None:\n",
        "        count_matrix.next[next_char] = increment_count(char, sequence[:-1], count_matrix.next[next_char])\n",
        "    elif sum(count_matrix.counts.values()) > PARAMS['threshold']:\n",
        "        vocab = count_matrix.next.keys()\n",
        "        initial_matrix = {i:0 for i in vocab}\n",
        "        initial_matrix[char] += 1\n",
        "        count_matrix.next = {i:CountMatrix(vocab, initial_matrix) for i in vocab}\n",
        "    \n",
        "    return count_matrix"
      ],
      "metadata": {
        "id": "fbyL-PrDkC3M"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def iterate_counts(data: Dataset, n: int, count_matrix: CountMatrix):\n",
        "    for idx, char in enumerate(data[n:]):\n",
        "        idx = n + idx\n",
        "        sequence = data[idx-n:idx]\n",
        "        \n",
        "        count_matrix = increment_count(data[idx], sequence, count_matrix)\n",
        "    return count_matrix"
      ],
      "metadata": {
        "id": "hOkVP9N4kC03"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Building Matrix...\")\n",
        "count_matrix = CountMatrix(vocab=train_data.idx_to_char.keys())\n",
        "\n",
        "print(\"Fitting...\")\n",
        "for i in range(PARAMS['train_iterations']):\n",
        "    print(\"Iteration {}\".format(i+1))\n",
        "    count_matrix = iterate_counts(train_data, PARAMS['n'], count_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNrYxiVrkCvs",
        "outputId": "c8ab1a01-f3e0-4dcd-fee1-66ade4c2bf58"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building Matrix...\n",
            "Fitting...\n",
            "Iteration 1\n",
            "Iteration 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def probabilities_from_counts(counts: dict):\n",
        "    # add one smoothing\n",
        "    counts = {key:counts[key]+1 for key in counts.keys()}\n",
        "    \n",
        "    probabilities = {key: counts[key] / sum(counts.values()) for key in counts.keys()}\n",
        "    prob_sum = sum(probabilities.values())\n",
        "    assert(abs(prob_sum - 1) < 0.0001), \"Probabilities should sum to 1.0 but got {}\".format(prob_sum)\n",
        "    \n",
        "    return probabilities"
      ],
      "metadata": {
        "id": "HE-thMVtkaTM"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_probabilities_for_sequence(sequence: list, count_matrix: CountMatrix):\n",
        "    # return counts if sequence has been exhausted\n",
        "    if len(sequence) == 0:\n",
        "        return count_matrix.counts\n",
        "    \n",
        "    next_char = sequence[-1]\n",
        "    \n",
        "    if count_matrix.next[next_char] is not None:\n",
        "        return get_probabilities_for_sequence(sequence[:-1], count_matrix.next[next_char])\n",
        "    else:\n",
        "        return probabilities_from_counts(count_matrix.counts)"
      ],
      "metadata": {
        "id": "6M4S8aoKkaQV"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_loss(target_prob):\n",
        "    return -math.log(target_prob, 2)"
      ],
      "metadata": {
        "id": "i3QHqUCSkcc9"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval(data: Dataset, n: int, count_matrix: CountMatrix):\n",
        "    print(\"Evaluating...\")\n",
        "    \n",
        "    counter = 0\n",
        "    running_loss = 0\n",
        "    running_acc = 0\n",
        "    \n",
        "    for idx, char in enumerate(data[n:]):\n",
        "        idx = n + idx\n",
        "        sequence = data[idx-n:idx]\n",
        "\n",
        "        probabilities: dict = get_probabilities_for_sequence(sequence, count_matrix)\n",
        "        pred: str = max(probabilities, key=probabilities.get)\n",
        "        target: str = data[idx]\n",
        "        target_prob: float = probabilities[target]\n",
        "        \n",
        "        running_loss += calc_loss(target_prob)\n",
        "        running_acc += 1 if target == pred else 0\n",
        "        counter += 1\n",
        "        \n",
        "    return running_loss / counter, running_acc / counter"
      ],
      "metadata": {
        "id": "j5RN2hu_kcaW"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss, train_acc = eval(train_data, PARAMS['n'], count_matrix)\n",
        "print(\"Train Loss: {:.3f}\\t\\t|\\tTrain Accuracy: {:.2f}%\".format(train_loss, train_acc*100))\n",
        "\n",
        "val_loss, val_acc = eval(val_data, PARAMS['n'], count_matrix)\n",
        "print(\"Validation Loss: {:.3f}\\t\\t|\\tValidation Accuracy: {:.2f}%\".format(val_loss, val_acc*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNVup5Jjkl8w",
        "outputId": "795984fd-ffe2-4bfb-91d2-8af0294cb4b0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating...\n",
            "Train Loss: 2.373\t\t|\tTrain Accuracy: 58.43%\n",
            "Evaluating...\n",
            "Validation Loss: 3.389\t\t|\tValidation Accuracy: 43.35%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if len(PARAMS['test_data']) > 0:\n",
        "    test_loss, test_acc = eval(test_data, PARAMS['n'], count_matrix)\n",
        "    print(\"Test Loss: {:.3f}\\t\\t|\\tTest Accuracy: {:.2f}%\".format(test_loss, test_acc*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sb_q1oiAkl6s",
        "outputId": "b75a7301-0369-48d4-a5cb-52e90e5692b9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating...\n",
            "Test Loss: 3.383\t\t|\tTest Accuracy: 43.52%\n"
          ]
        }
      ]
    }
  ]
}